{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing - X-ray Bone Fracture Detection\n",
    "\n",
    "This notebook demonstrates various preprocessing techniques using OpenCV.\n",
    "\n",
    "## Steps:\n",
    "1. Import libraries\n",
    "2. Load sample images\n",
    "3. Test preprocessing techniques\n",
    "4. Compare methods\n",
    "5. Build preprocessing pipeline\n",
    "6. Process full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our utilities\n",
    "from utils.preprocess import XRayPreprocessor\n",
    "from utils.data_loader import DatasetLoader\n",
    "from utils.visualization import XRayVisualizer\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"✅ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample fractured X-ray\n",
    "loader = DatasetLoader('../data')\n",
    "train_paths, train_labels = loader.load_data_paths('train')\n",
    "\n",
    "# Get a fractured sample\n",
    "fractured_indices = [i for i, label in enumerate(train_labels) if label == 1]\n",
    "sample_path = train_paths[fractured_indices[0]] if fractured_indices else train_paths[0]\n",
    "\n",
    "print(f\"Sample image: {sample_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display original\n",
    "original = cv2.imread(sample_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "viz = XRayVisualizer()\n",
    "viz.show_image(original, \"Original X-ray\")\n",
    "\n",
    "print(f\"Image shape: {original.shape}\")\n",
    "print(f\"Data type: {original.dtype}\")\n",
    "print(f\"Min pixel: {original.min()}\")\n",
    "print(f\"Max pixel: {original.max()}\")\n",
    "print(f\"Mean pixel: {original.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Individual Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = XRayPreprocessor(target_size=(224, 224))\n",
    "\n",
    "resized = preprocessor.resize_image(original)\n",
    "viz.compare_images(\n",
    "    [original, resized],\n",
    "    [f'Original {original.shape}', f'Resized {resized.shape}']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Denoising Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different denoising methods\n",
    "gaussian_denoised = preprocessor.denoise_gaussian(resized)\n",
    "bilateral_denoised = preprocessor.denoise_bilateral(resized)\n",
    "nlm_denoised = preprocessor.denoise_nlm(resized)\n",
    "\n",
    "viz.show_grid(\n",
    "    [resized, gaussian_denoised, bilateral_denoised, nlm_denoised],\n",
    "    ['Original', 'Gaussian', 'Bilateral', 'NLM Denoising'],\n",
    "    rows=2, cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Contrast Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contrast enhancement methods\n",
    "clahe_enhanced = preprocessor.enhance_contrast_clahe(resized)\n",
    "hist_enhanced = preprocessor.enhance_contrast_histogram(resized)\n",
    "\n",
    "viz.show_grid(\n",
    "    [resized, clahe_enhanced, hist_enhanced],\n",
    "    ['Original', 'CLAHE', 'Histogram Equalization'],\n",
    "    rows=1, cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare histograms\n",
    "viz.compare_histograms(\n",
    "    [resized, clahe_enhanced, hist_enhanced],\n",
    "    ['Original', 'CLAHE', 'Histogram Eq.'],\n",
    "    title='Contrast Enhancement Comparison'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sharpening\n",
    "sharpened = preprocessor.sharpen_image(resized, strength=1.0)\n",
    "\n",
    "viz.compare_images(\n",
    "    [resized, sharpened],\n",
    "    ['Original', 'Sharpened']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalization\n",
    "normalized_minmax = preprocessor.normalize_image(resized, method='minmax')\n",
    "normalized_standard = preprocessor.normalize_image(resized, method='standard')\n",
    "\n",
    "viz.show_grid(\n",
    "    [resized, normalized_minmax, normalized_standard],\n",
    "    ['Original', 'MinMax Normalized', 'Standard Normalized'],\n",
    "    rows=1, cols=3\n",
    ")\n",
    "\n",
    "print(\"MinMax normalized range:\", normalized_minmax.min(), \"to\", normalized_minmax.max())\n",
    "print(\"Standard normalized range:\", normalized_standard.min(), \"to\", normalized_standard.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the complete preprocessing pipeline\n",
    "preprocessor.visualize_preprocessing_steps(sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Pipeline on Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 5 random images\n",
    "test_indices = np.random.choice(len(train_paths), 5, replace=False)\n",
    "test_paths = [train_paths[i] for i in test_indices]\n",
    "\n",
    "preprocessed_images = []\n",
    "for path in test_paths:\n",
    "    img = preprocessor.preprocess_full_pipeline(path)\n",
    "    if img is not None:\n",
    "        preprocessed_images.append(img)\n",
    "\n",
    "# Display\n",
    "viz.show_grid(\n",
    "    preprocessed_images,\n",
    "    [f'Image {i+1}' for i in range(len(preprocessed_images))],\n",
    "    rows=1, cols=5\n",
    ")\n",
    "\n",
    "print(f\"✅ Successfully preprocessed {len(preprocessed_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch processing on a small subset\n",
    "subset_paths = train_paths[:100]  # First 100 images\n",
    "\n",
    "print(f\"Processing {len(subset_paths)} images...\")\n",
    "processed = preprocessor.preprocess_batch(subset_paths, show_progress=True)\n",
    "\n",
    "print(f\"\\n✅ Processed {len(processed)}/{len(subset_paths)} images\")\n",
    "print(f\"Success rate: {100*len(processed)/len(subset_paths):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Original vs Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compare\n",
    "comparison_path = train_paths[0]\n",
    "original_img = cv2.imread(comparison_path, cv2.IMREAD_GRAYSCALE)\n",
    "processed_img = preprocessor.preprocess_full_pipeline(comparison_path)\n",
    "\n",
    "# Resize processed for fair comparison\n",
    "processed_display = (processed_img * 255).astype(np.uint8)\n",
    "\n",
    "viz.compare_images(\n",
    "    [original_img, processed_display],\n",
    "    [f'Original\\n{original_img.shape}', f'Preprocessed\\n{processed_display.shape}']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Process Full Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This will process the entire dataset and may take a long time!\n",
    "# Uncomment to run\n",
    "\n",
    "# PROCESS_FULL_DATASET = False\n",
    "# \n",
    "# if PROCESS_FULL_DATASET:\n",
    "#     from utils.preprocess import preprocess_directory\n",
    "#     \n",
    "#     print(\"Processing training set...\")\n",
    "#     preprocess_directory(\n",
    "#         input_dir='../data/train',\n",
    "#         output_dir='../data/preprocessed/train',\n",
    "#         target_size=(224, 224)\n",
    "#     )\n",
    "#     \n",
    "#     print(\"\\nProcessing validation set...\")\n",
    "#     preprocess_directory(\n",
    "#         input_dir='../data/validation',\n",
    "#         output_dir='../data/preprocessed/validation',\n",
    "#         target_size=(224, 224)\n",
    "#     )\n",
    "#     \n",
    "#     print(\"\\n✅ Full dataset preprocessed!\")\n",
    "# else:\n",
    "#     print(\"⚠️ Set PROCESS_FULL_DATASET = True to process the entire dataset\")\n",
    "\n",
    "print(\"⚠️ Uncomment the code above to process the full dataset\")\n",
    "print(\"This may take several hours depending on dataset size!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Preprocessing Pipeline:\n",
    "1. **Load Image** → Grayscale\n",
    "2. **Remove Borders** → Remove black edges\n",
    "3. **Resize** → 224x224 pixels\n",
    "4. **Denoise** → Gaussian blur (kernel=5)\n",
    "5. **Enhance** → CLAHE (clip_limit=2.0)\n",
    "6. **Normalize** → [0, 1] range\n",
    "\n",
    "### Key Findings:\n",
    "- CLAHE works best for X-ray contrast enhancement\n",
    "- Gaussian denoising is fast and effective\n",
    "- Normalization to [0,1] prepares data for neural networks\n",
    "\n",
    "### Next Steps:\n",
    "1. Move to `03_data_augmentation.ipynb` for augmentation\n",
    "2. Or proceed to model training with preprocessed data\n",
    "\n",
    "### Notes:\n",
    "- Preprocessing is consistent across all images\n",
    "- Pipeline can be adjusted via config.py\n",
    "- Save preprocessed images or process on-the-fly during training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
